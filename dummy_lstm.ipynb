{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T16:27:31.160576097Z",
     "start_time": "2026-02-13T16:27:31.134022112Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from typing import Literal\n",
    "import ast\n",
    "import numpy as np\n",
    "import sys\n",
    "# from pympler import asizeof"
   ],
   "id": "f2037ceb45219a13",
   "outputs": [],
   "execution_count": 79
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-13T13:25:26.921132162Z",
     "start_time": "2026-02-13T13:25:22.466998097Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-13 15:25:24.610251: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T13:27:09.234581472Z",
     "start_time": "2026-02-13T13:27:08.142867449Z"
    }
   },
   "cell_type": "code",
   "source": "source_df = pd.read_csv(\"data/llm-classification-finetuning/train.csv\")",
   "id": "989749a86a37379d",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T13:27:10.055881077Z",
     "start_time": "2026-02-13T13:27:10.019148317Z"
    }
   },
   "cell_type": "code",
   "source": "source_df = source_df.sample(10000, ignore_index=True)",
   "id": "8afc4c4ad59a7332",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T13:27:11.104534058Z",
     "start_time": "2026-02-13T13:27:11.053002309Z"
    }
   },
   "cell_type": "code",
   "source": "source_df",
   "id": "7c29411fff07c42",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "              id                 model_a             model_b  \\\n",
       "0     2339905997              alpaca-13b    RWKV-4-Raven-14B   \n",
       "1     2648237572                claude-1          claude-2.0   \n",
       "2     3443365547              vicuna-13b          gpt-4-0613   \n",
       "3     2957381608              gpt-4-0613    llama-2-70b-chat   \n",
       "4     2673925671               vicuna-7b         chatglm2-6b   \n",
       "...          ...                     ...                 ...   \n",
       "9995  3749118402              claude-2.1    claude-instant-1   \n",
       "9996   704185085  codellama-34b-instruct  gpt-3.5-turbo-0613   \n",
       "9997   998594060              gpt-4-0613  gpt-3.5-turbo-1106   \n",
       "9998   985925841              vicuna-33b         chatglm2-6b   \n",
       "9999  1485568397         llama-2-7b-chat           vicuna-7b   \n",
       "\n",
       "                                                 prompt  \\\n",
       "0          [\"Write code in C to print 'Hello world!\\\"\"]   \n",
       "1     [\"Emily's voice quivered with excitement, \\\"Do...   \n",
       "2     [\"what is heavier, 10kg of feathers or 1 kg of...   \n",
       "3     [\"What is the longest first name in history?\",...   \n",
       "4     [\"for the following reaction, 0.410 moles of c...   \n",
       "...                                                 ...   \n",
       "9995  [\"I need your help in survival with little mon...   \n",
       "9996  [\"Hi! Please what is the onomatopoeia for the ...   \n",
       "9997  [\"Can you find me the top five front end build...   \n",
       "9998  [\"Top measures of goodness of fit for supervis...   \n",
       "9999  [\"Is this sentence grammatically correct?\",\"Af...   \n",
       "\n",
       "                                             response_a  \\\n",
       "0     [\"#include<stdio.h>\\nint main() {\\nprintf(\\\"He...   \n",
       "1     [\"I apologize, but I do not feel comfortable d...   \n",
       "2     [\"Both are the same weight, as they both have ...   \n",
       "3     [\"The longest first name in history is believe...   \n",
       "4     [\"To determine the formula for the limiting re...   \n",
       "...                                                 ...   \n",
       "9995  [\"Here are some suggestions for surviving with...   \n",
       "9996  [\"The onomatopoeia for the sound of a body eme...   \n",
       "9997  [\"Sure, here are some of the top front-end bui...   \n",
       "9998  [\"In supervised regression, goodness of fit me...   \n",
       "9999  [\"No, the sentence is not grammatically correc...   \n",
       "\n",
       "                                             response_b  winner_model_a  \\\n",
       "0     [\"#include <stdio.h>\\nint main() {\\n    printf...               0   \n",
       "1     [\"I apologize, but I do not feel comfortable r...               0   \n",
       "2     [\"10kg of feathers is heavier than 1kg of lead.\"]               0   \n",
       "3     [\"The longest first name in history is a matte...               0   \n",
       "4     [\"The limiting reactant is the substance that ...               1   \n",
       "...                                                 ...             ...   \n",
       "9995  [\"Here are some tips for surviving on a very l...               0   \n",
       "9996  [\"The onomatopoeia for the sound of a body eme...               0   \n",
       "9997  [\"| Front End Builder | Drag and Drop | Beginn...               0   \n",
       "9998  [\"There are several measures of the goodness o...               1   \n",
       "9999  [\"Yes, the sentence is grammatically correct.\"...               0   \n",
       "\n",
       "      winner_model_b  winner_tie  \n",
       "0                  1           0  \n",
       "1                  1           0  \n",
       "2                  1           0  \n",
       "3                  0           1  \n",
       "4                  0           0  \n",
       "...              ...         ...  \n",
       "9995               0           1  \n",
       "9996               1           0  \n",
       "9997               0           1  \n",
       "9998               0           0  \n",
       "9999               1           0  \n",
       "\n",
       "[10000 rows x 9 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2339905997</td>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>RWKV-4-Raven-14B</td>\n",
       "      <td>[\"Write code in C to print 'Hello world!\\\"\"]</td>\n",
       "      <td>[\"#include&lt;stdio.h&gt;\\nint main() {\\nprintf(\\\"He...</td>\n",
       "      <td>[\"#include &lt;stdio.h&gt;\\nint main() {\\n    printf...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2648237572</td>\n",
       "      <td>claude-1</td>\n",
       "      <td>claude-2.0</td>\n",
       "      <td>[\"Emily's voice quivered with excitement, \\\"Do...</td>\n",
       "      <td>[\"I apologize, but I do not feel comfortable d...</td>\n",
       "      <td>[\"I apologize, but I do not feel comfortable r...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3443365547</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[\"what is heavier, 10kg of feathers or 1 kg of...</td>\n",
       "      <td>[\"Both are the same weight, as they both have ...</td>\n",
       "      <td>[\"10kg of feathers is heavier than 1kg of lead.\"]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2957381608</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>llama-2-70b-chat</td>\n",
       "      <td>[\"What is the longest first name in history?\",...</td>\n",
       "      <td>[\"The longest first name in history is believe...</td>\n",
       "      <td>[\"The longest first name in history is a matte...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2673925671</td>\n",
       "      <td>vicuna-7b</td>\n",
       "      <td>chatglm2-6b</td>\n",
       "      <td>[\"for the following reaction, 0.410 moles of c...</td>\n",
       "      <td>[\"To determine the formula for the limiting re...</td>\n",
       "      <td>[\"The limiting reactant is the substance that ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>3749118402</td>\n",
       "      <td>claude-2.1</td>\n",
       "      <td>claude-instant-1</td>\n",
       "      <td>[\"I need your help in survival with little mon...</td>\n",
       "      <td>[\"Here are some suggestions for surviving with...</td>\n",
       "      <td>[\"Here are some tips for surviving on a very l...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>704185085</td>\n",
       "      <td>codellama-34b-instruct</td>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>[\"Hi! Please what is the onomatopoeia for the ...</td>\n",
       "      <td>[\"The onomatopoeia for the sound of a body eme...</td>\n",
       "      <td>[\"The onomatopoeia for the sound of a body eme...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>998594060</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>[\"Can you find me the top five front end build...</td>\n",
       "      <td>[\"Sure, here are some of the top front-end bui...</td>\n",
       "      <td>[\"| Front End Builder | Drag and Drop | Beginn...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>985925841</td>\n",
       "      <td>vicuna-33b</td>\n",
       "      <td>chatglm2-6b</td>\n",
       "      <td>[\"Top measures of goodness of fit for supervis...</td>\n",
       "      <td>[\"In supervised regression, goodness of fit me...</td>\n",
       "      <td>[\"There are several measures of the goodness o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1485568397</td>\n",
       "      <td>llama-2-7b-chat</td>\n",
       "      <td>vicuna-7b</td>\n",
       "      <td>[\"Is this sentence grammatically correct?\",\"Af...</td>\n",
       "      <td>[\"No, the sentence is not grammatically correc...</td>\n",
       "      <td>[\"Yes, the sentence is grammatically correct.\"...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 9 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T13:27:26.350671020Z",
     "start_time": "2026-02-13T13:27:26.218462003Z"
    }
   },
   "cell_type": "code",
   "source": "round(source_df.memory_usage(deep=True).sum() / 1024 / 1024, 2)",
   "id": "7e4267bce2f73aa6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.98"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Make each sample as \"[role user token] prompt [role model token] answer\"",
   "id": "d34250d045ecc54c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T13:27:31.388863886Z",
     "start_time": "2026-02-13T13:27:31.344211379Z"
    }
   },
   "cell_type": "code",
   "source": "source_df",
   "id": "fb53b0b1278e9a40",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "              id                 model_a             model_b  \\\n",
       "0     2339905997              alpaca-13b    RWKV-4-Raven-14B   \n",
       "1     2648237572                claude-1          claude-2.0   \n",
       "2     3443365547              vicuna-13b          gpt-4-0613   \n",
       "3     2957381608              gpt-4-0613    llama-2-70b-chat   \n",
       "4     2673925671               vicuna-7b         chatglm2-6b   \n",
       "...          ...                     ...                 ...   \n",
       "9995  3749118402              claude-2.1    claude-instant-1   \n",
       "9996   704185085  codellama-34b-instruct  gpt-3.5-turbo-0613   \n",
       "9997   998594060              gpt-4-0613  gpt-3.5-turbo-1106   \n",
       "9998   985925841              vicuna-33b         chatglm2-6b   \n",
       "9999  1485568397         llama-2-7b-chat           vicuna-7b   \n",
       "\n",
       "                                                 prompt  \\\n",
       "0          [\"Write code in C to print 'Hello world!\\\"\"]   \n",
       "1     [\"Emily's voice quivered with excitement, \\\"Do...   \n",
       "2     [\"what is heavier, 10kg of feathers or 1 kg of...   \n",
       "3     [\"What is the longest first name in history?\",...   \n",
       "4     [\"for the following reaction, 0.410 moles of c...   \n",
       "...                                                 ...   \n",
       "9995  [\"I need your help in survival with little mon...   \n",
       "9996  [\"Hi! Please what is the onomatopoeia for the ...   \n",
       "9997  [\"Can you find me the top five front end build...   \n",
       "9998  [\"Top measures of goodness of fit for supervis...   \n",
       "9999  [\"Is this sentence grammatically correct?\",\"Af...   \n",
       "\n",
       "                                             response_a  \\\n",
       "0     [\"#include<stdio.h>\\nint main() {\\nprintf(\\\"He...   \n",
       "1     [\"I apologize, but I do not feel comfortable d...   \n",
       "2     [\"Both are the same weight, as they both have ...   \n",
       "3     [\"The longest first name in history is believe...   \n",
       "4     [\"To determine the formula for the limiting re...   \n",
       "...                                                 ...   \n",
       "9995  [\"Here are some suggestions for surviving with...   \n",
       "9996  [\"The onomatopoeia for the sound of a body eme...   \n",
       "9997  [\"Sure, here are some of the top front-end bui...   \n",
       "9998  [\"In supervised regression, goodness of fit me...   \n",
       "9999  [\"No, the sentence is not grammatically correc...   \n",
       "\n",
       "                                             response_b  winner_model_a  \\\n",
       "0     [\"#include <stdio.h>\\nint main() {\\n    printf...               0   \n",
       "1     [\"I apologize, but I do not feel comfortable r...               0   \n",
       "2     [\"10kg of feathers is heavier than 1kg of lead.\"]               0   \n",
       "3     [\"The longest first name in history is a matte...               0   \n",
       "4     [\"The limiting reactant is the substance that ...               1   \n",
       "...                                                 ...             ...   \n",
       "9995  [\"Here are some tips for surviving on a very l...               0   \n",
       "9996  [\"The onomatopoeia for the sound of a body eme...               0   \n",
       "9997  [\"| Front End Builder | Drag and Drop | Beginn...               0   \n",
       "9998  [\"There are several measures of the goodness o...               1   \n",
       "9999  [\"Yes, the sentence is grammatically correct.\"...               0   \n",
       "\n",
       "      winner_model_b  winner_tie  \n",
       "0                  1           0  \n",
       "1                  1           0  \n",
       "2                  1           0  \n",
       "3                  0           1  \n",
       "4                  0           0  \n",
       "...              ...         ...  \n",
       "9995               0           1  \n",
       "9996               1           0  \n",
       "9997               0           1  \n",
       "9998               0           0  \n",
       "9999               1           0  \n",
       "\n",
       "[10000 rows x 9 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2339905997</td>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>RWKV-4-Raven-14B</td>\n",
       "      <td>[\"Write code in C to print 'Hello world!\\\"\"]</td>\n",
       "      <td>[\"#include&lt;stdio.h&gt;\\nint main() {\\nprintf(\\\"He...</td>\n",
       "      <td>[\"#include &lt;stdio.h&gt;\\nint main() {\\n    printf...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2648237572</td>\n",
       "      <td>claude-1</td>\n",
       "      <td>claude-2.0</td>\n",
       "      <td>[\"Emily's voice quivered with excitement, \\\"Do...</td>\n",
       "      <td>[\"I apologize, but I do not feel comfortable d...</td>\n",
       "      <td>[\"I apologize, but I do not feel comfortable r...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3443365547</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[\"what is heavier, 10kg of feathers or 1 kg of...</td>\n",
       "      <td>[\"Both are the same weight, as they both have ...</td>\n",
       "      <td>[\"10kg of feathers is heavier than 1kg of lead.\"]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2957381608</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>llama-2-70b-chat</td>\n",
       "      <td>[\"What is the longest first name in history?\",...</td>\n",
       "      <td>[\"The longest first name in history is believe...</td>\n",
       "      <td>[\"The longest first name in history is a matte...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2673925671</td>\n",
       "      <td>vicuna-7b</td>\n",
       "      <td>chatglm2-6b</td>\n",
       "      <td>[\"for the following reaction, 0.410 moles of c...</td>\n",
       "      <td>[\"To determine the formula for the limiting re...</td>\n",
       "      <td>[\"The limiting reactant is the substance that ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>3749118402</td>\n",
       "      <td>claude-2.1</td>\n",
       "      <td>claude-instant-1</td>\n",
       "      <td>[\"I need your help in survival with little mon...</td>\n",
       "      <td>[\"Here are some suggestions for surviving with...</td>\n",
       "      <td>[\"Here are some tips for surviving on a very l...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>704185085</td>\n",
       "      <td>codellama-34b-instruct</td>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>[\"Hi! Please what is the onomatopoeia for the ...</td>\n",
       "      <td>[\"The onomatopoeia for the sound of a body eme...</td>\n",
       "      <td>[\"The onomatopoeia for the sound of a body eme...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>998594060</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>[\"Can you find me the top five front end build...</td>\n",
       "      <td>[\"Sure, here are some of the top front-end bui...</td>\n",
       "      <td>[\"| Front End Builder | Drag and Drop | Beginn...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>985925841</td>\n",
       "      <td>vicuna-33b</td>\n",
       "      <td>chatglm2-6b</td>\n",
       "      <td>[\"Top measures of goodness of fit for supervis...</td>\n",
       "      <td>[\"In supervised regression, goodness of fit me...</td>\n",
       "      <td>[\"There are several measures of the goodness o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1485568397</td>\n",
       "      <td>llama-2-7b-chat</td>\n",
       "      <td>vicuna-7b</td>\n",
       "      <td>[\"Is this sentence grammatically correct?\",\"Af...</td>\n",
       "      <td>[\"No, the sentence is not grammatically correc...</td>\n",
       "      <td>[\"Yes, the sentence is grammatically correct.\"...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 9 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T13:28:04.097453278Z",
     "start_time": "2026-02-13T13:28:04.015222868Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def split_text_re(text):\n",
    "    text = text.strip(\"[]\")\n",
    "    matches = re.findall(r'\"([^\"]*)\"', text)\n",
    "    return matches\n",
    "\n",
    "def split_text(text):\n",
    "    val = ast.literal_eval(text)\n",
    "    if not isinstance(val, list):\n",
    "        raise ValueError(\"text must be a list\")\n",
    "    return val\n",
    "\n",
    "def add_tech_tokens(text: list, token_type: str):\n",
    "    if token_type not in [\"user\", \"model\"]:\n",
    "        raise ValueError(\"token_type must be either user or model\")\n",
    "    minor_token = \"<SUBTURN> \"\n",
    "    role = \"<USR> \" if token_type == \"user\" else \"<RESPONSE> \"\n",
    "    text = \" \".join([minor_token+t for t in text])\n",
    "    text = role+text\n",
    "    return text\n",
    "\n",
    "def process_text(text: str, text_type: Literal[\"user\", \"model\"]):\n",
    "    try:\n",
    "        parts = split_text(text)\n",
    "    except ValueError:\n",
    "        parts = split_text(text.replace(\"null\", \"\\\"\\\"\"))\n",
    "    except Exception:\n",
    "        parts = split_text_re(text)\n",
    "    return add_tech_tokens(parts, token_type=text_type)\n",
    "\n",
    "def modify_train(df: pd.DataFrame):\n",
    "    df = df.copy()\n",
    "    df[\"prompt\"] = df[\"prompt\"].apply(lambda x: process_text(x, \"user\"))\n",
    "    df[\"response_a\"] = df[\"response_a\"].apply(lambda x: process_text(x, \"model\"))\n",
    "    df[\"response_b\"] = df[\"response_b\"].apply(lambda x: process_text(x, \"model\"))\n",
    "    return df\n"
   ],
   "id": "6026774f7d751fd6",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T13:28:07.704966680Z",
     "start_time": "2026-02-13T13:28:07.656965697Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# r = split_text(source_df.loc[12, 'prompt'])\n",
    "# add_tech_tokens(r, \"user\")\n"
   ],
   "id": "4303c9024eab9c02",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T16:23:04.186269983Z",
     "start_time": "2026-02-13T16:23:03.846373737Z"
    }
   },
   "cell_type": "code",
   "source": "new_df = modify_train(source_df)",
   "id": "bda9c1dc0170e68c",
   "outputs": [],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T16:23:05.923464725Z",
     "start_time": "2026-02-13T16:23:05.796757291Z"
    }
   },
   "cell_type": "code",
   "source": "round(new_df.memory_usage(deep=True).sum() / 1024 / 1024, 2)",
   "id": "4d606a88a6fb1999",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.97"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T16:23:06.077675986Z",
     "start_time": "2026-02-13T16:23:06.023793085Z"
    }
   },
   "cell_type": "code",
   "source": [
    "new_df[\"response_a\"] = new_df[\"prompt\"] + \" \" + new_df[\"response_a\"]\n",
    "new_df[\"response_a\"] = new_df[\"prompt\"] + \" \" + new_df[\"response_a\"]\n",
    "new_df.rename(columns={\"response_a\": \"prompt_response_a\", \"response_b\": \"prompt_response_b\"}, inplace=True)\n",
    "new_df.drop(columns=[\"prompt\"], inplace=True)\n"
   ],
   "id": "a098a4ef8bfd8f89",
   "outputs": [],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T16:23:06.864137469Z",
     "start_time": "2026-02-13T16:23:06.779267721Z"
    }
   },
   "cell_type": "code",
   "source": "new_df[['winner_model_a', 'winner_model_b', 'winner_tie']].drop_duplicates()",
   "id": "4da5b09d2dd445ce",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   winner_model_a  winner_model_b  winner_tie\n",
       "0               0               1           0\n",
       "3               0               0           1\n",
       "4               1               0           0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T13:56:06.276911598Z",
     "start_time": "2026-02-13T13:56:06.158674914Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# new_df['winner_model_a'] =\\\n",
    "#     new_df.apply(lambda row: row['winner_tie'] if row['winner_tie'] else row['winner_model_a'], axis=1)\n",
    "#\n",
    "# new_df['winner_model_b'] =\\\n",
    "#     new_df.apply(lambda row: row['winner_tie'] if row['winner_tie'] else row['winner_model_b'], axis=1)"
   ],
   "id": "a5e0b5363c2c26db",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T16:23:11.039157772Z",
     "start_time": "2026-02-13T16:23:10.955292821Z"
    }
   },
   "cell_type": "code",
   "source": "new_df",
   "id": "8b96a59389a6f42d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "              id                 model_a             model_b  \\\n",
       "0     2339905997              alpaca-13b    RWKV-4-Raven-14B   \n",
       "1     2648237572                claude-1          claude-2.0   \n",
       "2     3443365547              vicuna-13b          gpt-4-0613   \n",
       "3     2957381608              gpt-4-0613    llama-2-70b-chat   \n",
       "4     2673925671               vicuna-7b         chatglm2-6b   \n",
       "...          ...                     ...                 ...   \n",
       "9995  3749118402              claude-2.1    claude-instant-1   \n",
       "9996   704185085  codellama-34b-instruct  gpt-3.5-turbo-0613   \n",
       "9997   998594060              gpt-4-0613  gpt-3.5-turbo-1106   \n",
       "9998   985925841              vicuna-33b         chatglm2-6b   \n",
       "9999  1485568397         llama-2-7b-chat           vicuna-7b   \n",
       "\n",
       "                                      prompt_response_a  \\\n",
       "0     <USR> <SUBTURN> Write code in C to print 'Hell...   \n",
       "1     <USR> <SUBTURN> Emily's voice quivered with ex...   \n",
       "2     <USR> <SUBTURN> what is heavier, 10kg of feath...   \n",
       "3     <USR> <SUBTURN> What is the longest first name...   \n",
       "4     <USR> <SUBTURN> for the following reaction, 0....   \n",
       "...                                                 ...   \n",
       "9995  <USR> <SUBTURN> I need your help in survival w...   \n",
       "9996  <USR> <SUBTURN> Hi! Please what is the onomato...   \n",
       "9997  <USR> <SUBTURN> Can you find me the top five f...   \n",
       "9998  <USR> <SUBTURN> Top measures of goodness of fi...   \n",
       "9999  <USR> <SUBTURN> Is this sentence grammatically...   \n",
       "\n",
       "                                      prompt_response_b  winner_model_a  \\\n",
       "0     <RESPONSE> <SUBTURN> #include <stdio.h>\\nint m...               0   \n",
       "1     <RESPONSE> <SUBTURN> I apologize, but I do not...               0   \n",
       "2     <RESPONSE> <SUBTURN> 10kg of feathers is heavi...               0   \n",
       "3     <RESPONSE> <SUBTURN> The longest first name in...               0   \n",
       "4     <RESPONSE> <SUBTURN> The limiting reactant is ...               1   \n",
       "...                                                 ...             ...   \n",
       "9995  <RESPONSE> <SUBTURN> Here are some tips for su...               0   \n",
       "9996  <RESPONSE> <SUBTURN> The onomatopoeia for the ...               0   \n",
       "9997  <RESPONSE> <SUBTURN> | Front End Builder | Dra...               0   \n",
       "9998  <RESPONSE> <SUBTURN> There are several measure...               1   \n",
       "9999  <RESPONSE> <SUBTURN> Yes, the sentence is gram...               0   \n",
       "\n",
       "      winner_model_b  winner_tie  \n",
       "0                  1           0  \n",
       "1                  1           0  \n",
       "2                  1           0  \n",
       "3                  0           1  \n",
       "4                  0           0  \n",
       "...              ...         ...  \n",
       "9995               0           1  \n",
       "9996               1           0  \n",
       "9997               0           1  \n",
       "9998               0           0  \n",
       "9999               1           0  \n",
       "\n",
       "[10000 rows x 8 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt_response_a</th>\n",
       "      <th>prompt_response_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2339905997</td>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>RWKV-4-Raven-14B</td>\n",
       "      <td>&lt;USR&gt; &lt;SUBTURN&gt; Write code in C to print 'Hell...</td>\n",
       "      <td>&lt;RESPONSE&gt; &lt;SUBTURN&gt; #include &lt;stdio.h&gt;\\nint m...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2648237572</td>\n",
       "      <td>claude-1</td>\n",
       "      <td>claude-2.0</td>\n",
       "      <td>&lt;USR&gt; &lt;SUBTURN&gt; Emily's voice quivered with ex...</td>\n",
       "      <td>&lt;RESPONSE&gt; &lt;SUBTURN&gt; I apologize, but I do not...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3443365547</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>&lt;USR&gt; &lt;SUBTURN&gt; what is heavier, 10kg of feath...</td>\n",
       "      <td>&lt;RESPONSE&gt; &lt;SUBTURN&gt; 10kg of feathers is heavi...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2957381608</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>llama-2-70b-chat</td>\n",
       "      <td>&lt;USR&gt; &lt;SUBTURN&gt; What is the longest first name...</td>\n",
       "      <td>&lt;RESPONSE&gt; &lt;SUBTURN&gt; The longest first name in...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2673925671</td>\n",
       "      <td>vicuna-7b</td>\n",
       "      <td>chatglm2-6b</td>\n",
       "      <td>&lt;USR&gt; &lt;SUBTURN&gt; for the following reaction, 0....</td>\n",
       "      <td>&lt;RESPONSE&gt; &lt;SUBTURN&gt; The limiting reactant is ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>3749118402</td>\n",
       "      <td>claude-2.1</td>\n",
       "      <td>claude-instant-1</td>\n",
       "      <td>&lt;USR&gt; &lt;SUBTURN&gt; I need your help in survival w...</td>\n",
       "      <td>&lt;RESPONSE&gt; &lt;SUBTURN&gt; Here are some tips for su...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>704185085</td>\n",
       "      <td>codellama-34b-instruct</td>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>&lt;USR&gt; &lt;SUBTURN&gt; Hi! Please what is the onomato...</td>\n",
       "      <td>&lt;RESPONSE&gt; &lt;SUBTURN&gt; The onomatopoeia for the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>998594060</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>&lt;USR&gt; &lt;SUBTURN&gt; Can you find me the top five f...</td>\n",
       "      <td>&lt;RESPONSE&gt; &lt;SUBTURN&gt; | Front End Builder | Dra...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>985925841</td>\n",
       "      <td>vicuna-33b</td>\n",
       "      <td>chatglm2-6b</td>\n",
       "      <td>&lt;USR&gt; &lt;SUBTURN&gt; Top measures of goodness of fi...</td>\n",
       "      <td>&lt;RESPONSE&gt; &lt;SUBTURN&gt; There are several measure...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1485568397</td>\n",
       "      <td>llama-2-7b-chat</td>\n",
       "      <td>vicuna-7b</td>\n",
       "      <td>&lt;USR&gt; &lt;SUBTURN&gt; Is this sentence grammatically...</td>\n",
       "      <td>&lt;RESPONSE&gt; &lt;SUBTURN&gt; Yes, the sentence is gram...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 8 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 78
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Tokenize samples",
   "id": "775dd57f4bab6cde"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T13:48:25.516083492Z",
     "start_time": "2026-02-13T13:48:25.220091291Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ],
   "id": "a05f495e3de8cab9",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T13:48:25.626895152Z",
     "start_time": "2026-02-13T13:48:25.542769604Z"
    }
   },
   "cell_type": "code",
   "source": [
    "special_tokens = [\"<SUBTURN>\", \"<USR>\", \"<RESPONSE>\"]\n",
    "\n",
    "tokenizer.add_special_tokens({\n",
    "    \"additional_special_tokens\": special_tokens\n",
    "})"
   ],
   "id": "3593e5ec734accfa",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T15:35:37.045683653Z",
     "start_time": "2026-02-13T15:35:37.025411049Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tokenize_process_column(col: pd.Series):\n",
    "    data = (\n",
    "        col\n",
    "        .astype(str)\n",
    "        .apply(lambda s: s.encode(\"utf-8\", \"ignore\").decode(\"utf-8\"))\n",
    "    )\n",
    "    data = data.tolist()\n",
    "\n",
    "    encoded_tokens = tokenizer(data,\n",
    "        return_attention_mask=True,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        padding=True,\n",
    "        return_tensors=\"np\"\n",
    "        )\n",
    "    return encoded_tokens\n"
   ],
   "id": "9a91cababf483161",
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T15:35:45.677420843Z",
     "start_time": "2026-02-13T15:35:41.347126140Z"
    }
   },
   "cell_type": "code",
   "source": [
    "encA = tokenize_process_column(new_df['prompt_response_a'])\n",
    "encB = tokenize_process_column(new_df['prompt_response_b'])\n"
   ],
   "id": "34a05681175e3c61",
   "outputs": [],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T13:31:22.236671017Z",
     "start_time": "2026-02-13T13:31:22.160048267Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer.vocab_size",
   "id": "95b6a7dba47862c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T13:31:24.332282813Z",
     "start_time": "2026-02-13T13:31:24.266203429Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer.get_added_vocab()",
   "id": "890303c7ce5a63e5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'[PAD]': 0,\n",
       " '[UNK]': 100,\n",
       " '[CLS]': 101,\n",
       " '[SEP]': 102,\n",
       " '[MASK]': 103,\n",
       " '<SUBTURN>': 30522,\n",
       " '<USR>': 30523,\n",
       " '<RESPONSE>': 30524}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T13:31:45.439351942Z",
     "start_time": "2026-02-13T13:31:45.369954730Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer.get_vocab()[\"<USR>\"]",
   "id": "1782777c5e8a1e7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30523"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T13:31:45.954741581Z",
     "start_time": "2026-02-13T13:31:45.888844653Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer.vocab_size",
   "id": "4f8f1f81b699941e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T20:24:54.537800516Z",
     "start_time": "2026-02-10T20:24:54.426386059Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vocab_size = tokenizer.vocab_size\n",
    "embed_dim=128\n",
    "embedding = tf.keras.layers.Embedding(\n",
    "    input_dim=vocab_size,\n",
    "    output_dim=embed_dim\n",
    ")"
   ],
   "id": "dc189739b7b4ea2c",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T15:49:48.720984946Z",
     "start_time": "2026-02-13T15:49:48.701694705Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "ec7f165129759b29",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T15:50:27.724569395Z",
     "start_time": "2026-02-13T15:50:27.678726990Z"
    }
   },
   "cell_type": "code",
   "source": [
    "seq_length = encA[\"input_ids\"].shape[1]\n",
    "\n",
    "ids_a  = tf.keras.Input(shape=(seq_length,), dtype=tf.int32, name=\"ids_a\")\n",
    "mask_a = tf.keras.Input(shape=(seq_length,), dtype=tf.int32, name=\"mask_a\")\n",
    "\n",
    "ids_b  = tf.keras.Input(shape=(seq_length,), dtype=tf.int32, name=\"ids_b\")\n",
    "mask_b = tf.keras.Input(shape=(seq_length,), dtype=tf.int32, name=\"mask_b\")\n"
   ],
   "id": "dcdf3920cdba5e17",
   "outputs": [],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T15:52:41.148412329Z",
     "start_time": "2026-02-13T15:52:39.595876012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vocab_size = tokenizer.vocab_size\n",
    "embed_dim=128\n",
    "embedding = tf.keras.layers.Embedding(vocab_size, embed_dim, name=\"emb\")\n",
    "\n",
    "lstm_units = 128\n",
    "shared_lstm = tf.keras.layers.LSTM(lstm_units, name=\"shared_lstm\")"
   ],
   "id": "de6e61e4eda79f07",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-13 17:52:40.814723: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-02-13 17:52:41.022760: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-02-13 17:52:41.023143: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-02-13 17:52:41.026167: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-02-13 17:52:41.026475: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-02-13 17:52:41.026671: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-02-13 17:52:41.091401: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-02-13 17:52:41.091668: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-02-13 17:52:41.091885: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-02-13 17:52:41.092018: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2285 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T16:11:09.075139895Z",
     "start_time": "2026-02-13T16:11:08.994921364Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def shared_pipeline(ids, mask):\n",
    "    x = embedding(ids)\n",
    "    m = tf.cast(mask, tf.bool)\n",
    "    h = shared_lstm(x, mask=m)\n",
    "    return h"
   ],
   "id": "bdcbc7af66590e8f",
   "outputs": [],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T16:14:54.698383320Z",
     "start_time": "2026-02-13T16:14:53.136520007Z"
    }
   },
   "cell_type": "code",
   "source": [
    "shared_output_a, shared_output_b, = shared_pipeline(ids_a, mask_a), shared_pipeline(ids_b, mask_b)\n",
    "\n",
    "feat = tf.keras.layers.Concatenate(name=\"concat\")([shared_output_a, shared_output_b])"
   ],
   "id": "da4116c407aa96a3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-13 18:14:53.555969: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    }
   ],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T16:15:42.786672524Z",
     "start_time": "2026-02-13T16:15:42.731947622Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = tf.keras.layers.Dense(128, activation=\"relu\")(feat)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "out = tf.keras.layers.Dense(3, activation=\"softmax\", name=\"y\")(x)"
   ],
   "id": "5f6b30172f3c043e",
   "outputs": [],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T16:20:54.753210793Z",
     "start_time": "2026-02-13T16:20:54.689447921Z"
    }
   },
   "cell_type": "code",
   "source": "model = tf.keras.Model(inputs=[ids_a, mask_a, ids_b, mask_b], outputs=out)",
   "id": "ae40fab10f96f66",
   "outputs": [],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T16:27:37.777210280Z",
     "start_time": "2026-02-13T16:27:37.751565213Z"
    }
   },
   "cell_type": "code",
   "source": "y = new_df[[\"winner_model_a\", \"winner_model_b\", \"winner_tie\"]].to_numpy(dtype=np.float32)",
   "id": "22b17cd8f3b757af",
   "outputs": [],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T16:28:59.811735042Z",
     "start_time": "2026-02-13T16:28:59.762130597Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "X = {\n",
    "    \"ids_a\": encA[\"input_ids\"],\n",
    "    \"mask_a\": encA[\"attention_mask\"],\n",
    "    \"ids_b\": encB[\"input_ids\"],\n",
    "    \"mask_b\": encB[\"attention_mask\"],\n",
    "}\n"
   ],
   "id": "2ad2a95e98d1ae3f",
   "outputs": [],
   "execution_count": 82
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T16:33:07.176953242Z",
     "start_time": "2026-02-13T16:29:16.257955777Z"
    }
   },
   "cell_type": "code",
   "source": "model.fit(X, y, batch_size=32, epochs=8, validation_split=0.1, shuffle=True)",
   "id": "a723acf4ba3b34b0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fdb4c5214d0>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 83
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a2c4a92b068f5b9b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
