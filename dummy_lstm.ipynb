{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T17:54:25.532630260Z",
     "start_time": "2026-02-04T17:54:25.485194370Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from typing import Literal\n",
    "import ast\n",
    "import sys\n",
    "from pympler import asizeof"
   ],
   "id": "f2037ceb45219a13",
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-04T17:53:42.128380475Z",
     "start_time": "2026-02-04T17:53:40.133238144Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-04 19:53:40.783630: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T17:53:43.086583029Z",
     "start_time": "2026-02-04T17:53:42.178358624Z"
    }
   },
   "cell_type": "code",
   "source": "source_df = pd.read_csv(\"data/llm-classification-finetuning/train.csv\")",
   "id": "989749a86a37379d",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T17:53:43.245732143Z",
     "start_time": "2026-02-04T17:53:43.132295067Z"
    }
   },
   "cell_type": "code",
   "source": "round(source_df.memory_usage(deep=True).sum() / 1024 / 1024, 2)",
   "id": "7e4267bce2f73aa6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190.7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Make each sample as \"[role user token] prompt [role model token] answer\"",
   "id": "d34250d045ecc54c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T17:53:43.297230769Z",
     "start_time": "2026-02-04T17:53:43.249242601Z"
    }
   },
   "cell_type": "code",
   "source": "source_df",
   "id": "fb53b0b1278e9a40",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               id             model_a              model_b  \\\n",
       "0           30192  gpt-4-1106-preview           gpt-4-0613   \n",
       "1           53567           koala-13b           gpt-4-0613   \n",
       "2           65089  gpt-3.5-turbo-0613       mistral-medium   \n",
       "3           96401    llama-2-13b-chat  mistral-7b-instruct   \n",
       "4          198779           koala-13b   gpt-3.5-turbo-0314   \n",
       "...           ...                 ...                  ...   \n",
       "57472  4294656694          gpt-4-0613             claude-1   \n",
       "57473  4294692063          claude-2.0     llama-2-13b-chat   \n",
       "57474  4294710549            claude-1           alpaca-13b   \n",
       "57475  4294899228              palm-2       tulu-2-dpo-70b   \n",
       "57476  4294947231  gemini-pro-dev-api   gpt-4-1106-preview   \n",
       "\n",
       "                                                  prompt  \\\n",
       "0      [\"Is it morally right to try to have a certain...   \n",
       "1      [\"What is the difference between marriage lice...   \n",
       "2      [\"explain function calling. how would you call...   \n",
       "3      [\"How can I create a test set for a very rare ...   \n",
       "4      [\"What is the best way to travel from Tel-Aviv...   \n",
       "...                                                  ...   \n",
       "57472  [\"A simple mnemonic for \\u03c0:\\n\\\"How I wish ...   \n",
       "57473  [\"In python, implement a naive Bayes with gaus...   \n",
       "57474  [\"is it unethical to work on building weapons?...   \n",
       "57475  [\"If a bait contains 0,0025% bromadiolon then ...   \n",
       "57476  [\"three kids eat three apples in three days, h...   \n",
       "\n",
       "                                              response_a  \\\n",
       "0      [\"The question of whether it is morally right ...   \n",
       "1      [\"A marriage license is a legal document that ...   \n",
       "2      [\"Function calling is the process of invoking ...   \n",
       "3      [\"Creating a test set for a very rare category...   \n",
       "4      [\"The best way to travel from Tel Aviv to Jeru...   \n",
       "...                                                  ...   \n",
       "57472  [\"Sure, let's break it down:\\n\\n1. \\\"How\\\" has...   \n",
       "57473  [\"Here is an implementation of a naive Bayes c...   \n",
       "57474  [\"Working on weapons technology raises some et...   \n",
       "57475  [\"Bromadiolone is a rodenticide which is most ...   \n",
       "57476                                      [\"27 apples\"]   \n",
       "\n",
       "                                              response_b  winner_model_a  \\\n",
       "0      [\"As an AI, I don't have personal beliefs or o...               1   \n",
       "1      [\"A marriage license and a marriage certificat...               0   \n",
       "2      [\"Function calling is the process of invoking ...               0   \n",
       "3      [\"When building a classifier for a very rare c...               1   \n",
       "4      [\"The best way to travel from Tel-Aviv to Jeru...               0   \n",
       "...                                                  ...             ...   \n",
       "57472  [\"Here is how that mnemonic represents the dig...               1   \n",
       "57473  [\"Sure! Here's an implementation of a naive Ba...               1   \n",
       "57474  [\"It depends on the context. Weapons can be us...               1   \n",
       "57475  [\"As an AI language model, I do not promote or...               0   \n",
       "57476  [\"If three kids eat three apples in three days...               1   \n",
       "\n",
       "       winner_model_b  winner_tie  \n",
       "0                   0           0  \n",
       "1                   1           0  \n",
       "2                   0           1  \n",
       "3                   0           0  \n",
       "4                   1           0  \n",
       "...               ...         ...  \n",
       "57472               0           0  \n",
       "57473               0           0  \n",
       "57474               0           0  \n",
       "57475               1           0  \n",
       "57476               0           0  \n",
       "\n",
       "[57477 rows x 9 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30192</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[\"Is it morally right to try to have a certain...</td>\n",
       "      <td>[\"The question of whether it is morally right ...</td>\n",
       "      <td>[\"As an AI, I don't have personal beliefs or o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53567</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[\"What is the difference between marriage lice...</td>\n",
       "      <td>[\"A marriage license is a legal document that ...</td>\n",
       "      <td>[\"A marriage license and a marriage certificat...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65089</td>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>mistral-medium</td>\n",
       "      <td>[\"explain function calling. how would you call...</td>\n",
       "      <td>[\"Function calling is the process of invoking ...</td>\n",
       "      <td>[\"Function calling is the process of invoking ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96401</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>mistral-7b-instruct</td>\n",
       "      <td>[\"How can I create a test set for a very rare ...</td>\n",
       "      <td>[\"Creating a test set for a very rare category...</td>\n",
       "      <td>[\"When building a classifier for a very rare c...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198779</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-3.5-turbo-0314</td>\n",
       "      <td>[\"What is the best way to travel from Tel-Aviv...</td>\n",
       "      <td>[\"The best way to travel from Tel Aviv to Jeru...</td>\n",
       "      <td>[\"The best way to travel from Tel-Aviv to Jeru...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57472</th>\n",
       "      <td>4294656694</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>claude-1</td>\n",
       "      <td>[\"A simple mnemonic for \\u03c0:\\n\\\"How I wish ...</td>\n",
       "      <td>[\"Sure, let's break it down:\\n\\n1. \\\"How\\\" has...</td>\n",
       "      <td>[\"Here is how that mnemonic represents the dig...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57473</th>\n",
       "      <td>4294692063</td>\n",
       "      <td>claude-2.0</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>[\"In python, implement a naive Bayes with gaus...</td>\n",
       "      <td>[\"Here is an implementation of a naive Bayes c...</td>\n",
       "      <td>[\"Sure! Here's an implementation of a naive Ba...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57474</th>\n",
       "      <td>4294710549</td>\n",
       "      <td>claude-1</td>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>[\"is it unethical to work on building weapons?...</td>\n",
       "      <td>[\"Working on weapons technology raises some et...</td>\n",
       "      <td>[\"It depends on the context. Weapons can be us...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57475</th>\n",
       "      <td>4294899228</td>\n",
       "      <td>palm-2</td>\n",
       "      <td>tulu-2-dpo-70b</td>\n",
       "      <td>[\"If a bait contains 0,0025% bromadiolon then ...</td>\n",
       "      <td>[\"Bromadiolone is a rodenticide which is most ...</td>\n",
       "      <td>[\"As an AI language model, I do not promote or...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57476</th>\n",
       "      <td>4294947231</td>\n",
       "      <td>gemini-pro-dev-api</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>[\"three kids eat three apples in three days, h...</td>\n",
       "      <td>[\"27 apples\"]</td>\n",
       "      <td>[\"If three kids eat three apples in three days...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57477 rows × 9 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T17:53:43.455547032Z",
     "start_time": "2026-02-04T17:53:43.331395971Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def split_text_re(text):\n",
    "    text = text.strip(\"[]\")\n",
    "    matches = re.findall(r'\"([^\"]*)\"', text)\n",
    "    return matches\n",
    "\n",
    "def split_text(text):\n",
    "    val = ast.literal_eval(text)\n",
    "    if not isinstance(val, list):\n",
    "        raise ValueError(\"text must be a list\")\n",
    "    return val\n",
    "\n",
    "def add_tech_tokens(text: list, token_type: str):\n",
    "    if token_type not in [\"user\", \"model\"]:\n",
    "        raise ValueError(\"token_type must be either user or model\")\n",
    "    minor_token = \"<SUBTURN> \"\n",
    "    role = \"<USR> \" if token_type == \"user\" else \"<RESPONSE> \"\n",
    "    text = \" \".join([minor_token+t for t in text])\n",
    "    text = role+text\n",
    "    return text\n",
    "\n",
    "def process_text(text: str, text_type: Literal[\"user\", \"model\"]):\n",
    "    try:\n",
    "        parts = split_text(text)\n",
    "    except ValueError:\n",
    "        parts = split_text(text.replace(\"null\", \"\\\"\\\"\"))\n",
    "    except Exception:\n",
    "        parts = split_text_re(text)\n",
    "    return add_tech_tokens(parts, token_type=text_type)\n",
    "\n",
    "def modify_train(df: pd.DataFrame):\n",
    "    df = df.copy()\n",
    "    df[\"prompt\"] = df[\"prompt\"].apply(lambda x: process_text(x, \"user\"))\n",
    "    df[\"response_a\"] = df[\"response_a\"].apply(lambda x: process_text(x, \"model\"))\n",
    "    df[\"response_b\"] = df[\"response_b\"].apply(lambda x: process_text(x, \"model\"))\n",
    "    return df\n"
   ],
   "id": "6026774f7d751fd6",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T17:53:44.221951898Z",
     "start_time": "2026-02-04T17:53:44.173059886Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# r = split_text(source_df.loc[12, 'prompt'])\n",
    "# add_tech_tokens(r, \"user\")\n"
   ],
   "id": "4303c9024eab9c02",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T17:53:47.114751148Z",
     "start_time": "2026-02-04T17:53:45.378305571Z"
    }
   },
   "cell_type": "code",
   "source": "new_df = modify_train(source_df)",
   "id": "bda9c1dc0170e68c",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T17:53:47.183403629Z",
     "start_time": "2026-02-04T17:53:47.115669115Z"
    }
   },
   "cell_type": "code",
   "source": "round(new_df.memory_usage(deep=True).sum() / 1024 / 1024, 2)",
   "id": "4d606a88a6fb1999",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "213.34"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T17:53:47.335310014Z",
     "start_time": "2026-02-04T17:53:47.191400990Z"
    }
   },
   "cell_type": "code",
   "source": [
    "new_df[\"response_a\"] = new_df[\"prompt\"] + \" \" + new_df[\"response_a\"]\n",
    "new_df[\"response_a\"] = new_df[\"prompt\"] + \" \" + new_df[\"response_a\"]\n",
    "new_df.rename(columns={\"response_a\": \"prompt_response_a\", \"response_b\": \"prompt_response_b\"}, inplace=True)\n",
    "new_df.drop(columns=[\"prompt\"], inplace=True)\n"
   ],
   "id": "a098a4ef8bfd8f89",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T17:53:47.392826484Z",
     "start_time": "2026-02-04T17:53:47.336336960Z"
    }
   },
   "cell_type": "code",
   "source": "new_df",
   "id": "8b96a59389a6f42d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               id             model_a              model_b  \\\n",
       "0           30192  gpt-4-1106-preview           gpt-4-0613   \n",
       "1           53567           koala-13b           gpt-4-0613   \n",
       "2           65089  gpt-3.5-turbo-0613       mistral-medium   \n",
       "3           96401    llama-2-13b-chat  mistral-7b-instruct   \n",
       "4          198779           koala-13b   gpt-3.5-turbo-0314   \n",
       "...           ...                 ...                  ...   \n",
       "57472  4294656694          gpt-4-0613             claude-1   \n",
       "57473  4294692063          claude-2.0     llama-2-13b-chat   \n",
       "57474  4294710549            claude-1           alpaca-13b   \n",
       "57475  4294899228              palm-2       tulu-2-dpo-70b   \n",
       "57476  4294947231  gemini-pro-dev-api   gpt-4-1106-preview   \n",
       "\n",
       "                                       prompt_response_a  \\\n",
       "0      <USR> <SUBTURN> Is it morally right to try to ...   \n",
       "1      <USR> <SUBTURN> What is the difference between...   \n",
       "2      <USR> <SUBTURN> explain function calling. how ...   \n",
       "3      <USR> <SUBTURN> How can I create a test set fo...   \n",
       "4      <USR> <SUBTURN> What is the best way to travel...   \n",
       "...                                                  ...   \n",
       "57472  <USR> <SUBTURN> A simple mnemonic for π:\\n\"How...   \n",
       "57473  <USR> <SUBTURN> In python, implement a naive B...   \n",
       "57474  <USR> <SUBTURN> is it unethical to work on bui...   \n",
       "57475  <USR> <SUBTURN> If a bait contains 0,0025% bro...   \n",
       "57476  <USR> <SUBTURN> three kids eat three apples in...   \n",
       "\n",
       "                                       prompt_response_b  winner_model_a  \\\n",
       "0      <RESPONSE> <SUBTURN> As an AI, I don't have pe...               1   \n",
       "1      <RESPONSE> <SUBTURN> A marriage license and a ...               0   \n",
       "2      <RESPONSE> <SUBTURN> Function calling is the p...               0   \n",
       "3      <RESPONSE> <SUBTURN> When building a classifie...               1   \n",
       "4      <RESPONSE> <SUBTURN> The best way to travel fr...               0   \n",
       "...                                                  ...             ...   \n",
       "57472  <RESPONSE> <SUBTURN> Here is how that mnemonic...               1   \n",
       "57473  <RESPONSE> <SUBTURN> Sure! Here's an implement...               1   \n",
       "57474  <RESPONSE> <SUBTURN> It depends on the context...               1   \n",
       "57475  <RESPONSE> <SUBTURN> As an AI language model, ...               0   \n",
       "57476  <RESPONSE> <SUBTURN> If three kids eat three a...               1   \n",
       "\n",
       "       winner_model_b  winner_tie  \n",
       "0                   0           0  \n",
       "1                   1           0  \n",
       "2                   0           1  \n",
       "3                   0           0  \n",
       "4                   1           0  \n",
       "...               ...         ...  \n",
       "57472               0           0  \n",
       "57473               0           0  \n",
       "57474               0           0  \n",
       "57475               1           0  \n",
       "57476               0           0  \n",
       "\n",
       "[57477 rows x 8 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt_response_a</th>\n",
       "      <th>prompt_response_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30192</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>&lt;USR&gt; &lt;SUBTURN&gt; Is it morally right to try to ...</td>\n",
       "      <td>&lt;RESPONSE&gt; &lt;SUBTURN&gt; As an AI, I don't have pe...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53567</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>&lt;USR&gt; &lt;SUBTURN&gt; What is the difference between...</td>\n",
       "      <td>&lt;RESPONSE&gt; &lt;SUBTURN&gt; A marriage license and a ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65089</td>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>mistral-medium</td>\n",
       "      <td>&lt;USR&gt; &lt;SUBTURN&gt; explain function calling. how ...</td>\n",
       "      <td>&lt;RESPONSE&gt; &lt;SUBTURN&gt; Function calling is the p...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96401</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>mistral-7b-instruct</td>\n",
       "      <td>&lt;USR&gt; &lt;SUBTURN&gt; How can I create a test set fo...</td>\n",
       "      <td>&lt;RESPONSE&gt; &lt;SUBTURN&gt; When building a classifie...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198779</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-3.5-turbo-0314</td>\n",
       "      <td>&lt;USR&gt; &lt;SUBTURN&gt; What is the best way to travel...</td>\n",
       "      <td>&lt;RESPONSE&gt; &lt;SUBTURN&gt; The best way to travel fr...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57472</th>\n",
       "      <td>4294656694</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>claude-1</td>\n",
       "      <td>&lt;USR&gt; &lt;SUBTURN&gt; A simple mnemonic for π:\\n\"How...</td>\n",
       "      <td>&lt;RESPONSE&gt; &lt;SUBTURN&gt; Here is how that mnemonic...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57473</th>\n",
       "      <td>4294692063</td>\n",
       "      <td>claude-2.0</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>&lt;USR&gt; &lt;SUBTURN&gt; In python, implement a naive B...</td>\n",
       "      <td>&lt;RESPONSE&gt; &lt;SUBTURN&gt; Sure! Here's an implement...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57474</th>\n",
       "      <td>4294710549</td>\n",
       "      <td>claude-1</td>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>&lt;USR&gt; &lt;SUBTURN&gt; is it unethical to work on bui...</td>\n",
       "      <td>&lt;RESPONSE&gt; &lt;SUBTURN&gt; It depends on the context...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57475</th>\n",
       "      <td>4294899228</td>\n",
       "      <td>palm-2</td>\n",
       "      <td>tulu-2-dpo-70b</td>\n",
       "      <td>&lt;USR&gt; &lt;SUBTURN&gt; If a bait contains 0,0025% bro...</td>\n",
       "      <td>&lt;RESPONSE&gt; &lt;SUBTURN&gt; As an AI language model, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57476</th>\n",
       "      <td>4294947231</td>\n",
       "      <td>gemini-pro-dev-api</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>&lt;USR&gt; &lt;SUBTURN&gt; three kids eat three apples in...</td>\n",
       "      <td>&lt;RESPONSE&gt; &lt;SUBTURN&gt; If three kids eat three a...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57477 rows × 8 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Tokenize samples",
   "id": "775dd57f4bab6cde"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T17:53:49.477691661Z",
     "start_time": "2026-02-04T17:53:49.213712061Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ],
   "id": "a05f495e3de8cab9",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T17:53:49.637659797Z",
     "start_time": "2026-02-04T17:53:49.606183619Z"
    }
   },
   "cell_type": "code",
   "source": [
    "special_tokens = [\"<SUBTURN>\", \"<USR>\", \"<RESPONSE>\"]\n",
    "\n",
    "tokenizer.add_special_tokens({\n",
    "    \"additional_special_tokens\": special_tokens\n",
    "})"
   ],
   "id": "3593e5ec734accfa",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T17:53:58.981339542Z",
     "start_time": "2026-02-04T17:53:58.844494129Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_for_tokens = pd.concat([new_df['prompt_response_a'], new_df['prompt_response_b']],\n",
    "                            ignore_index=True)\n",
    "\n",
    "data_for_tokens = (\n",
    "    data_for_tokens\n",
    "    .astype(str)\n",
    "    .apply(lambda s: s.encode(\"utf-8\", \"ignore\").decode(\"utf-8\"))\n",
    ")\n",
    "\n",
    "# print(data_for_tokens.memory_usage(deep=True) / 1024 / 1024)\n",
    "data_for_tokens = data_for_tokens.tolist()"
   ],
   "id": "81c45bbe75369f0",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T17:59:57.376172769Z",
     "start_time": "2026-02-04T17:59:57.329746962Z"
    }
   },
   "cell_type": "code",
   "source": [
    "len(data_for_tokens)\n",
    "test_data_for_tokens = data_for_tokens[:25000]"
   ],
   "id": "5474001d2b69b9c5",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T18:00:04.134329239Z",
     "start_time": "2026-02-04T18:00:00.342497472Z"
    }
   },
   "cell_type": "code",
   "source": [
    "enc = tokenizer(test_data_for_tokens,\n",
    "                return_attention_mask=True,\n",
    "                truncation=True,\n",
    "                max_length=512,\n",
    "                padding=True,\n",
    "                return_tensors=\"np\"\n",
    "                )\n",
    "\n"
   ],
   "id": "b4e17c66a7ffc477",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T18:00:05.648157377Z",
     "start_time": "2026-02-04T18:00:05.620012565Z"
    }
   },
   "cell_type": "code",
   "source": "len(test_data_for_tokens)",
   "id": "81cc2a762dfd1b70",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T18:00:07.693926924Z",
     "start_time": "2026-02-04T18:00:07.630625455Z"
    }
   },
   "cell_type": "code",
   "source": "len(\"\".join(test_data_for_tokens))",
   "id": "67d61114da8bfc27",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52562107"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T18:00:18.209735933Z",
     "start_time": "2026-02-04T18:00:18.164721342Z"
    }
   },
   "cell_type": "code",
   "source": "asizeof.asizeof(test_data_for_tokens) / 1024 / 1024",
   "id": "16735d83c70419e7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77.64669036865234"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T18:00:19.552941312Z",
     "start_time": "2026-02-04T18:00:19.524477137Z"
    }
   },
   "cell_type": "code",
   "source": "enc['input_ids'].nbytes / 1024 / 1024",
   "id": "4b7ec8f8d8f1d1e7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.65625"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T18:00:20.356127122Z",
     "start_time": "2026-02-04T18:00:20.310056186Z"
    }
   },
   "cell_type": "code",
   "source": "enc['attention_mask'].nbytes / 1024 / 1024\n",
   "id": "8c9ec3b2925ed32b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.65625"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T15:41:11.196378906Z",
     "start_time": "2026-02-04T15:40:11.298176791Z"
    }
   },
   "cell_type": "code",
   "source": "print(enc['input_ids'])",
   "id": "2c6ea312c36d9c11",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
